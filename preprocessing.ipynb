{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/tmp/ipykernel_235499/3152804180.py:118: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"Egen\": torch.tensor(E).squeeze().clone(),\n",
      "100000it [00:49, 2009.50it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 149\u001b[0m\n\u001b[1;32m    138\u001b[0m scalar \u001b[39m=\u001b[39m ScalerBase(\n\u001b[1;32m    139\u001b[0m     transfs\u001b[39m=\u001b[39m[\n\u001b[1;32m    140\u001b[0m         PowerTransformer(method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbox-cox\u001b[39m\u001b[39m\"\u001b[39m, standardize\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    146\u001b[0m     featurenames\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mE\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mz\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39malpha\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m    147\u001b[0m )\n\u001b[1;32m    148\u001b[0m arr \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mvstack(outD[\u001b[39m\"\u001b[39m\u001b[39mE_z_alpha_r\u001b[39m\u001b[39m\"\u001b[39m])[:\u001b[39m100\u001b[39m]\n\u001b[0;32m--> 149\u001b[0m scalar\u001b[39m.\u001b[39;49msave_scalar(arr)\n\u001b[1;32m    151\u001b[0m \u001b[39mfor\u001b[39;00m ievent \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(outD[\u001b[39m\"\u001b[39m\u001b[39mE_z_alpha_r\u001b[39m\u001b[39m\"\u001b[39m]))):\n\u001b[1;32m    152\u001b[0m     outD[\u001b[39m\"\u001b[39m\u001b[39mE_z_alpha_r\u001b[39m\u001b[39m\"\u001b[39m][ievent] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(\n\u001b[1;32m    153\u001b[0m         scalar\u001b[39m.\u001b[39mtransform(outD[\u001b[39m\"\u001b[39m\u001b[39mE_z_alpha_r\u001b[39m\u001b[39m\"\u001b[39m][ievent]\u001b[39m.\u001b[39mnumpy())\n\u001b[1;32m    154\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[28], line 43\u001b[0m, in \u001b[0;36mScalerBase.save_scalar\u001b[0;34m(self, pcs)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mplot_scaling(pcs)\n\u001b[1;32m     41\u001b[0m \u001b[39massert\u001b[39;00m pcs\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features\n\u001b[1;32m     42\u001b[0m pcs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mhstack(\n\u001b[0;32m---> 43\u001b[0m     [\n\u001b[1;32m     44\u001b[0m         logit(transf\u001b[39m.\u001b[39mfit_transform(arr\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)))\n\u001b[1;32m     45\u001b[0m         \u001b[39mfor\u001b[39;00m arr, transf \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(pcs\u001b[39m.\u001b[39mT, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransfs)\n\u001b[1;32m     46\u001b[0m     ]\n\u001b[1;32m     47\u001b[0m )\n\u001b[1;32m     48\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mplot_scaling(pcs, \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     50\u001b[0m joblib\u001b[39m.\u001b[39mdump(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransfs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscalerpath)\n",
      "Cell \u001b[0;32mIn[28], line 44\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mplot_scaling(pcs)\n\u001b[1;32m     41\u001b[0m \u001b[39massert\u001b[39;00m pcs\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features\n\u001b[1;32m     42\u001b[0m pcs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mhstack(\n\u001b[1;32m     43\u001b[0m     [\n\u001b[0;32m---> 44\u001b[0m         logit(transf\u001b[39m.\u001b[39;49mfit_transform(arr\u001b[39m.\u001b[39;49mreshape(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m)))\n\u001b[1;32m     45\u001b[0m         \u001b[39mfor\u001b[39;00m arr, transf \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(pcs\u001b[39m.\u001b[39mT, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransfs)\n\u001b[1;32m     46\u001b[0m     ]\n\u001b[1;32m     47\u001b[0m )\n\u001b[1;32m     48\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mplot_scaling(pcs, \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     50\u001b[0m joblib\u001b[39m.\u001b[39mdump(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransfs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscalerpath)\n",
      "Cell \u001b[0;32mIn[28], line 20\u001b[0m, in \u001b[0;36mlogit\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlogit\u001b[39m(p):\n\u001b[0;32m---> 20\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mlog(np\u001b[39m.\u001b[39;49mmax(\u001b[39m1e-8\u001b[39;49m,p)) \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39mlog(\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39mmin(\u001b[39m1\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1e-8\u001b[39m,p))\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mamax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/beegfs/desy/user/kaechben/.conda/envs/torch_jet/lib/python3.10/site-packages/numpy/core/fromnumeric.py:2793\u001b[0m, in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_amax_dispatcher)\n\u001b[1;32m   2678\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mamax\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue, initial\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue,\n\u001b[1;32m   2679\u001b[0m          where\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue):\n\u001b[1;32m   2680\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2681\u001b[0m \u001b[39m    Return the maximum of an array or maximum along an axis.\u001b[39;00m\n\u001b[1;32m   2682\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2791\u001b[0m \u001b[39m    5\u001b[39;00m\n\u001b[1;32m   2792\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2793\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapreduction(a, np\u001b[39m.\u001b[39;49mmaximum, \u001b[39m'\u001b[39;49m\u001b[39mmax\u001b[39;49m\u001b[39m'\u001b[39;49m, axis, \u001b[39mNone\u001b[39;49;00m, out,\n\u001b[1;32m   2794\u001b[0m                           keepdims\u001b[39m=\u001b[39;49mkeepdims, initial\u001b[39m=\u001b[39;49minitial, where\u001b[39m=\u001b[39;49mwhere)\n",
      "File \u001b[0;32m/beegfs/desy/user/kaechben/.conda/envs/torch_jet/lib/python3.10/site-packages/numpy/core/fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m             \u001b[39mreturn\u001b[39;00m reduction(axis\u001b[39m=\u001b[39maxis, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 86\u001b[0m \u001b[39mreturn\u001b[39;00m ufunc\u001b[39m.\u001b[39;49mreduce(obj, axis, dtype, out, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpasskwargs)\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PowerTransformer, StandardScaler, MinMaxScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "data_dir = \"/beegfs/desy/user/kaechben/calochallenge/\"\n",
    "mode=\"train\"\n",
    "\n",
    "electron_file = h5py.File(\n",
    "    data_dir + {\"train\": \"dataset_2_1.hdf5\", \"test\": \"dataset_2_2.hdf5\"}[mode], \"r\"\n",
    ")\n",
    "energies = electron_file[\"incident_energies\"][:]\n",
    "showers = electron_file[\"showers\"][:]\n",
    "\n",
    "outL = [\n",
    "    shower_to_pc(e)\n",
    "    for e in tqdm(zip(torch.tensor(showers), torch.tensor(energies)))\n",
    "]\n",
    "outD = {k: [e[k] for e in outL] for k in outL[0].keys()}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def shower_to_pc(args):\n",
    "    shower, E = args\n",
    "    shower, E = shower.clone(), E.clone()\n",
    "\n",
    "    shower = shower.reshape(num_z, num_alpha, num_r)\n",
    "    # assert shower.shape == etas.shape == phis.shape\n",
    "    idxs = torch.where(shower)\n",
    "    h_energy = shower[idxs]\n",
    "    z, alpha, r = idxs\n",
    "    z=z.float()+torch.rand(z.shape)\n",
    "    alpha=alpha+torch.rand(alpha.shape)\n",
    "    r=r+torch.rand(r.shape)\n",
    "    # hitsperlayer = (shower != 0).float().sum((1, 2))\n",
    "    # assert (\n",
    "    #     hitsperlayer[hitsperlayer != 0]\n",
    "    #     == torch.unique(idxs[0], sorted=True, return_counts=True)[1]\n",
    "    # ).all()\n",
    "    # zp = z - num_z / 2\n",
    "    # theta = torch.arctan(zp / r)\n",
    "    # eta = torch.log(torch.tan(theta / 2))\n",
    "    # phi = alpha\n",
    "    pc = torch.stack([h_energy, z, alpha, r,]).T\n",
    "    return {\n",
    "        \"Egen\": torch.tensor(E).squeeze().clone(),\n",
    "        \"E_z_alpha_r\": pc.clone(),\n",
    "    }\n",
    "\n",
    "\n",
    "# %%\n",
    "# creating instance of HighLevelFeatures class to handle geometry based on binning file\n",
    "class ScalerBase:\n",
    "    def __init__(self, transfs, featurenames: list[str]) -> None:\n",
    "        self.transfs = transfs\n",
    "        self.featurenames = featurenames\n",
    "        self.n_features = len(self.transfs)\n",
    "\n",
    "        self.scalerpath = Path(data_dir) / \"scaler.gz\"\n",
    "        if self.scalerpath.is_file():\n",
    "            self.transfs = joblib.load(self.scalerpath)\n",
    "\n",
    "    def save_scalar(self, pcs: torch.Tensor):\n",
    "        # The features need to be converted to numpy immediatly\n",
    "        # otherwise the queuflow afterwards doesnt work\n",
    "        assert pcs.dim() == 2\n",
    "        assert self.n_features == pcs.shape[1]\n",
    "        pcs = pcs.detach().cpu().numpy()\n",
    "        self.plot_scaling(pcs)\n",
    "\n",
    "        assert pcs.shape[1] == self.n_features\n",
    "        pcs = np.hstack(\n",
    "            [\n",
    "                transf.fit_transform(arr.reshape(-1, 1))\n",
    "                for arr, transf in zip(pcs.T, self.transfs)\n",
    "            ]\n",
    "        )\n",
    "        self.plot_scaling(pcs, True)\n",
    "\n",
    "        joblib.dump(self.transfs, self.scalerpath)\n",
    "\n",
    "    def transform(self, pcs: np.ndarray):\n",
    "        assert len(pcs.shape) == 2\n",
    "        assert pcs.shape[1] == self.n_features\n",
    "        return np.hstack(\n",
    "            [\n",
    "                transf.fit_transform(arr.reshape(-1, 1))\n",
    "                for arr, transf in zip(pcs.T, self.transfs)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def inverse_transform(self, pcs: torch.Tensor):\n",
    "        assert pcs.shape[-1] == self.n_features\n",
    "        orgshape = pcs.shape\n",
    "        dev = pcs.device\n",
    "        pcs = pcs.to(\"cpu\").detach().reshape(-1, self.n_features).numpy()\n",
    "\n",
    "        t_stacked = np.hstack(\n",
    "            [\n",
    "                transf.inverse_transform(arr.reshape(-1, 1))\n",
    "                for arr, transf in zip(pcs.T, self.transfs)\n",
    "            ]\n",
    "        )\n",
    "        return torch.from_numpy(t_stacked.reshape(*orgshape)).float().to(dev)\n",
    "\n",
    "    def plot_scaling(self, pcs, post=False):\n",
    "        for k, v in zip(self.featurenames, pcs.T):\n",
    "            fig, ax = plt.subplots(figsize=(10, 7))\n",
    "            ax.hist(v, bins=500)\n",
    "            fig.savefig(\n",
    "                Path(data_dir) / f\"{k}_post.png\"\n",
    "                if post\n",
    "                else Path(data_dir) / f\"{k}_pre.png\"\n",
    "            )\n",
    "            plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [15:21<00:00, 108.47it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_z = 9\n",
    "num_alpha = 16\n",
    "num_r = 45\n",
    "\n",
    "\n",
    "mode=\"train\"\n",
    "if mode == \"train\":\n",
    "    scalar = ScalerBase(\n",
    "        transfs=[\n",
    "            PowerTransformer(method=\"box-cox\", standardize=True),\n",
    "            MinMaxScaler(),\n",
    "            MinMaxScaler(),\n",
    "            MinMaxScaler(),\n",
    "\n",
    "        ],\n",
    "        featurenames=[\"E\", \"z\", \"alpha\", \"r\"],\n",
    "    )\n",
    "    arr = torch.vstack(outD[\"E_z_alpha_r\"])[:100]\n",
    "\n",
    "    scalar.save_scalar(arr)\n",
    "\n",
    "    for ievent in tqdm(range(len(outD[\"E_z_alpha_r\"]))):\n",
    "        outD[\"E_z_alpha_r\"][ievent] = torch.tensor(\n",
    "            scalar.transform(outD[\"E_z_alpha_r\"][ievent].numpy())\n",
    "        )\n",
    "    torch.save(outD, f\"{data_dir}pc_{mode}.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plt\u001b[39m.\u001b[39mhist([arr[:,\u001b[39m1\u001b[39;49m]]\u001b[39m.\u001b[39;49mnumpy())\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "[transf.transform(arr.reshape(-1, 1))             for arr, transf in zip(pcs.T, self.transfs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0152, dtype=torch.float64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[:,0].min()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([16026072., 24158207., 26290447., 24924452., 21597186., 17304647.,\n",
       "        12665503.,  8313108.,  4885378.,  2628468.]),\n",
       " array([0. , 0.9, 1.8, 2.7, 3.6, 4.5, 5.4, 6.3, 7.2, 8.1, 9. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(arr[:,1].numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_jet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
